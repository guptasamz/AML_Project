{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 16:54:20.179774: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-07 16:54:20.179837: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-07 16:54:20.180716: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-07 16:54:20.187948: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-07 16:54:21.086747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-07 16:54:24,073\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2023-12-07 16:54:24,183\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.layers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from ray import tune\n",
    "sns.set(rc={'figure.figsize':(9, 7)})\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# Coral Ordinal Function and Custom metric defining here\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "MODEL_PATH = '../data/models/'\n",
    "DATA_DIR = '../data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not to use in ipynb file\n",
    "# import argparse\n",
    "# # Create the parser\n",
    "# parser = argparse.ArgumentParser(description=\"Script for generating the deep ensemble hyperparameter results\")\n",
    "# # Add the --value argument\n",
    "# parser.add_argument('--dv', type=int, help=\"Data version\")\n",
    "# # Parse the arguments\n",
    "# args = parser.parse_args()\n",
    "# # Asking the user for their name\n",
    "# data_type = int(args.dv)\n",
    "\n",
    "data_type = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "version = 'stl_1'\n",
    "log_version = 'stl_1'\n",
    "EPOCHS = 200\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = ''\n",
    "if data_type != 4:\n",
    "\n",
    "    data_version = 'synthetic'\n",
    "\n",
    "    path = f'../data/new_data/data{data_type}/'\n",
    "\n",
    "    train_df = pd.read_csv(f'{path}/Data{data_type}_Train.csv')\n",
    "    val_df = pd.read_csv(f'{path}/Data{data_type}_Val.csv')\n",
    "    test_df = pd.read_csv(f'{path}/Data{data_type}_Test.csv')\n",
    "\n",
    "    tensor_train_data = torch.Tensor(train_df.Input1).unsqueeze(1)\n",
    "    tensor_train_label = torch.Tensor(train_df.Output)\n",
    "\n",
    "    tensor_val_data = torch.Tensor(val_df.Input1).unsqueeze(1)\n",
    "    tensor_val_label = torch.Tensor(val_df.Output)\n",
    "\n",
    "    tensor_test_data = torch.Tensor(test_df.Input1).unsqueeze(1)\n",
    "    tensor_test_label = torch.Tensor(test_df.Output)\n",
    "\n",
    "    train_dataset = TensorDataset(tensor_train_data, tensor_train_label)\n",
    "    val_dataset = TensorDataset(tensor_val_data, tensor_val_label)\n",
    "\n",
    "else:\n",
    "    data_version = 'household_power'\n",
    "    path = f'../data/{data_version}/'\n",
    "\n",
    "    # feature_x = pd.read_csv(f'{path}/feature_x.csv')\n",
    "    train_x = np.load(f'{path}/train_x.npy')\n",
    "    train_y = np.load(f'{path}/train_y.npy')\n",
    "\n",
    "    val_x = np.load(f'{path}/val_x.npy')\n",
    "    val_y = np.load(f'{path}/val_y.npy')\n",
    "\n",
    "    test_x = np.load(f'{path}/test_x.npy')\n",
    "    test_y = np.load(f'{path}/test_y.npy')\n",
    "\n",
    "    tensor_train_data = torch.Tensor(train_x)\n",
    "    tensor_train_label = torch.Tensor(train_y)\n",
    "\n",
    "    tensor_val_data = torch.Tensor(val_x)\n",
    "    tensor_val_label = torch.Tensor(val_y)\n",
    "\n",
    "    tensor_test_data = torch.Tensor(test_x)\n",
    "    tensor_test_label = torch.Tensor(test_y)\n",
    "\n",
    "    train_dataset = TensorDataset(tensor_train_data, tensor_train_label)\n",
    "    val_dataset = TensorDataset(tensor_val_data, tensor_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepEnsembleNet(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, n_layers):\n",
    "        super(DeepEnsembleNet, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        input_size = num_features\n",
    "\n",
    "        # Create 'n' hidden layers\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            input_size = hidden_size  # The output of each layer is the input to the next\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.mu = nn.Linear(hidden_size, 1)\n",
    "        self.var = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        mu = self.mu(x)\n",
    "        var = torch.exp(self.var(x))\n",
    "        return mu, var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_de(config):\n",
    "\n",
    "    hidden_size = int(config['hidden_size'])\n",
    "    num_layers = int(config['num_layers'])\n",
    "    patience = int(config['patience'])\n",
    "    batch_size = int(config['batch_size'])\n",
    "    num_models = int(config['num_models'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model_name = f'hs_{hidden_size}_nl_{num_layers}_do_{config[\"num_models\"]}_ep_{config[\"epochs\"]}_p_{config[\"patience\"]}_lr_{config[\"lr\"]}_bs_{batch_size}.pt'\n",
    "\n",
    "    models[f'{model_name}']= DeepEnsembleNet(config[\"num_features\"], hidden_size, num_layers)\n",
    "\n",
    "    device = 'cpu'\n",
    "    models[f'{model_name}'].to(device)\n",
    "    \n",
    "    best_model_dir = f'./models/'\n",
    "    pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True) \n",
    "    best_model_path = f'{best_model_dir}/hs_{hidden_size}_nl_{num_layers}_do_{config[\"num_models\"]}_ep_{config[\"epochs\"]}_p_{config[\"patience\"]}_lr_{config[\"lr\"]}_bs_{batch_size}'\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Construct ensemble\n",
    "    deep_ensemble = [DeepEnsembleNet(config[\"num_features\"], hidden_size, num_layers).to(device) for i in range(num_models)]\n",
    "    criterion = torch.nn.GaussianNLLLoss(eps=1e-02)\n",
    "    optimizers = [optim.Adam(m.parameters(), lr=config[\"lr\"]) for m in deep_ensemble]\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        # Train loop\n",
    "        for batch in train_loader:\n",
    "            x = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "\n",
    "            losses = []\n",
    "            mus = []\n",
    "            vars = []\n",
    "            for i, model in enumerate(deep_ensemble):\n",
    "                optimizers[i].zero_grad()\n",
    "                mu, var = model(x)\n",
    "                loss = criterion(mu, y, var)\n",
    "                loss.backward()\n",
    "                optimizers[i].step()\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                mus.append(mu)\n",
    "                vars.append(var)\n",
    "            loss = sum(losses)/len(losses)\n",
    "\n",
    "        # Validation loop to monitor early stopping\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_losses = []\n",
    "        for batch in val_loader:  # Assuming you have a validation data loader\n",
    "            x = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "\n",
    "            with torch.no_grad():  # No gradient calculation for validation data\n",
    "                for model in deep_ensemble:\n",
    "                    mu, var = model(x)\n",
    "                    val_loss = criterion(mu, y, var)\n",
    "                    val_losses.append(val_loss.item())\n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f'Early stopping triggered at epoch {epoch}')\n",
    "                break\n",
    "\n",
    "        print(f'Epoch: {epoch}|Train Loss: {loss}|Val Loss: {avg_val_loss}')\n",
    "    \n",
    "    tune.report(train_loss=loss,best_val_loss=best_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(num_samples=100, max_num_epochs=500):\n",
    "\n",
    "    if data_type != 4:\n",
    "        num_features = 1\n",
    "    else:\n",
    "        num_features = 7\n",
    "\n",
    "    ray.init()\n",
    "\n",
    "    config = {\n",
    "        \"num_features\": num_features,\n",
    "        \"hidden_size\": tune.quniform(1, 200, 1),\n",
    "        \"num_layers\": tune.quniform(2, 10, 1),\n",
    "        \"num_models\": 5,\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"epochs\": max_num_epochs,\n",
    "        \"patience\": tune.quniform(1, 50, 1),\n",
    "        \"batch_size\": tune.quniform(1, 20, 1)\n",
    "    }\n",
    "\n",
    "    from ray.tune.search import ConcurrencyLimiter\n",
    "    from ray.tune.search.bayesopt import BayesOptSearch\n",
    "    algo = BayesOptSearch(utility_kwargs={\"kind\": \"ucb\", \"kappa\": 2.5, \"xi\": 0.0})\n",
    "    algo = ConcurrencyLimiter(algo, max_concurrent=25)\n",
    "\n",
    "    result = tune.run(\n",
    "            tune.with_parameters(train_de),\n",
    "            config=config,\n",
    "            resources_per_trial={\"cpu\": 1},\n",
    "            metric=\"best_val_loss\",\n",
    "            mode=\"min\",\n",
    "            search_alg=algo,\n",
    "            num_samples=num_samples,\n",
    "            # max_concurrent_trials=20,\n",
    "            local_dir= f'/home/sgupta/WORK/Triplevel_transformer_model/baselines/hyperparameter_search',\n",
    "            name=f\"experiment_de_{data_type}\",\n",
    "            max_failures=7,\n",
    "            raise_on_failed_trial=False\n",
    "        )\n",
    "\n",
    "    temp = result.dataframe()   \n",
    "    hyperparams_path = f'./hyperparameter_search/'\n",
    "    temp.to_csv(f\"{hyperparams_path}/RAY_RESULTS_de_data{data_type}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 16:54:27,205\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2023-12-07 16:54:28,821\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-12-07 16:54:28,841\tWARNING bayesopt_search.py:421 -- BayesOpt search does not support quantization. Dropped quantization.\n",
      "2023-12-07 16:54:28,842\tWARNING bayesopt_search.py:431 -- BayesOpt does not support specific sampling methods. The Uniform sampler will be dropped.\n",
      "2023-12-07 16:54:28,842\tWARNING bayesopt_search.py:421 -- BayesOpt search does not support quantization. Dropped quantization.\n",
      "2023-12-07 16:54:28,843\tWARNING bayesopt_search.py:431 -- BayesOpt does not support specific sampling methods. The Uniform sampler will be dropped.\n",
      "2023-12-07 16:54:28,843\tWARNING bayesopt_search.py:431 -- BayesOpt does not support specific sampling methods. The LogUniform sampler will be dropped.\n",
      "2023-12-07 16:54:28,844\tWARNING bayesopt_search.py:421 -- BayesOpt search does not support quantization. Dropped quantization.\n",
      "2023-12-07 16:54:28,844\tWARNING bayesopt_search.py:431 -- BayesOpt does not support specific sampling methods. The Uniform sampler will be dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-12-07 17:01:48</td></tr>\n",
       "<tr><td>Running for: </td><td>00:07:20.01        </td></tr>\n",
       "<tr><td>Memory:      </td><td>18.3/94.3 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 10.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:TITAN)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  patience</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_de_a611d829</td><td>RUNNING </td><td>10.2.218.69:9777 </td><td style=\"text-align: right;\">      75.5335</td><td style=\"text-align: right;\">0.0950764 </td><td style=\"text-align: right;\">     7.85595</td><td style=\"text-align: right;\">  12.3745 </td></tr>\n",
       "<tr><td>train_de_3584e3e5</td><td>RUNNING </td><td>10.2.218.69:9839 </td><td style=\"text-align: right;\">      32.0477</td><td style=\"text-align: right;\">0.0156839 </td><td style=\"text-align: right;\">     2.46467</td><td style=\"text-align: right;\">  17.4573 </td></tr>\n",
       "<tr><td>train_de_c02439f6</td><td>RUNNING </td><td>10.2.218.69:9889 </td><td style=\"text-align: right;\">     120.622 </td><td style=\"text-align: right;\">0.0708365 </td><td style=\"text-align: right;\">     2.16468</td><td style=\"text-align: right;\">  19.4283 </td></tr>\n",
       "<tr><td>train_de_d83ddfbd</td><td>RUNNING </td><td>10.2.218.69:9928 </td><td style=\"text-align: right;\">     166.656 </td><td style=\"text-align: right;\">0.0213127 </td><td style=\"text-align: right;\">     3.4546 </td><td style=\"text-align: right;\">   4.48469</td></tr>\n",
       "<tr><td>train_de_8e30742c</td><td>RUNNING </td><td>10.2.218.69:10016</td><td style=\"text-align: right;\">      61.5442</td><td style=\"text-align: right;\">0.0525232 </td><td style=\"text-align: right;\">     5.45556</td><td style=\"text-align: right;\">   6.53335</td></tr>\n",
       "<tr><td>train_de_0d561399</td><td>RUNNING </td><td>10.2.218.69:10063</td><td style=\"text-align: right;\">     122.759 </td><td style=\"text-align: right;\">0.0140354 </td><td style=\"text-align: right;\">     4.33716</td><td style=\"text-align: right;\">   7.96088</td></tr>\n",
       "<tr><td>train_de_c04e5cb4</td><td>RUNNING </td><td>10.2.218.69:10139</td><td style=\"text-align: right;\">      91.7579</td><td style=\"text-align: right;\">0.0785391 </td><td style=\"text-align: right;\">     3.59739</td><td style=\"text-align: right;\">  10.7705 </td></tr>\n",
       "<tr><td>train_de_ad1564b5</td><td>RUNNING </td><td>10.2.218.69:10199</td><td style=\"text-align: right;\">     118.89  </td><td style=\"text-align: right;\">0.0047404 </td><td style=\"text-align: right;\">     6.86036</td><td style=\"text-align: right;\">   4.23996</td></tr>\n",
       "<tr><td>train_de_cec2b8ff</td><td>RUNNING </td><td>10.2.218.69:10238</td><td style=\"text-align: right;\">      13.9453</td><td style=\"text-align: right;\">0.0948937 </td><td style=\"text-align: right;\">     9.72506</td><td style=\"text-align: right;\">  16.3595 </td></tr>\n",
       "<tr><td>train_de_249c27b0</td><td>RUNNING </td><td>10.2.218.69:10332</td><td style=\"text-align: right;\">      61.6181</td><td style=\"text-align: right;\">0.00985744</td><td style=\"text-align: right;\">     7.47386</td><td style=\"text-align: right;\">   9.3629 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=9777)\u001b[0m /media/seconddrive/sgupta/anaconda3/envs/py39SAM/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "\u001b[2m\u001b[36m(train_de pid=9777)\u001b[0m   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:54:36,189 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42478104576; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(train_de pid=9889)\u001b[0m /media/seconddrive/sgupta/anaconda3/envs/py39SAM/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_de pid=9889)\u001b[0m   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:54:46,198 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42477588480; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(train_de pid=10016)\u001b[0m /media/seconddrive/sgupta/anaconda3/envs/py39SAM/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_de pid=10016)\u001b[0m   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_de pid=10139)\u001b[0m /media/seconddrive/sgupta/anaconda3/envs/py39SAM/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_de pid=10139)\u001b[0m   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:54:56,209 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42477084672; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[36m(train_de pid=10238)\u001b[0m /media/seconddrive/sgupta/anaconda3/envs/py39SAM/lib/python3.9/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_de pid=10238)\u001b[0m   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:55:06,220 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42476544000; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:55:16,232 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42476089344; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:55:26,244 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42475630592; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:55:36,256 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42475048960; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:55:46,269 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42474598400; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:55:56,280 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42474151936; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:56:06,293 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42473500672; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:56:16,303 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42473066496; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:56:26,313 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42472620032; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:56:36,325 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42472161280; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:56:46,335 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42471727104; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=9839)\u001b[0m Epoch: 0|Train Loss: -2.2496002197265623|Val Loss: -1.8243953763594911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:56:56,346 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42471292928; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:57:06,357 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42470817792; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:57:16,368 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42470363136; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:57:26,380 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42469916672; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=9889)\u001b[0m Epoch: 0|Train Loss: -0.5279855728149414|Val Loss: -1.3783716596492894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:57:36,392 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42469380096; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:57:46,403 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42509008896; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:57:56,414 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42508566528; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:58:06,425 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42508017664; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:58:16,436 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42507579392; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:58:26,445 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42507141120; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:58:36,456 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42506649600; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=10139)\u001b[0m Epoch: 0|Train Loss: -1.5490185499191285|Val Loss: -1.5364361486532916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:58:46,466 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42506211328; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=10016)\u001b[0m Epoch: 0|Train Loss: -0.8987990021705627|Val Loss: -1.2161260382973984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:58:56,475 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42505773056; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:59:06,485 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42505285632; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=9928)\u001b[0m Epoch: 0|Train Loss: -1.3088579416275024|Val Loss: -1.5483112057553579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:59:16,494 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42504839168; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:59:26,501 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42504392704; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=10063)\u001b[0m Epoch: 0|Train Loss: -1.0476930975914|Val Loss: -1.5319559609536166\n",
      "\u001b[2m\u001b[36m(train_de pid=9839)\u001b[0m Epoch: 1|Train Loss: -1.9840617179870605|Val Loss: -1.7526952851579427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:59:36,511 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42503905280; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:59:46,521 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42503450624; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 16:59:56,531 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42503016448; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=9777)\u001b[0m Epoch: 0|Train Loss: nan|Val Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:00:06,539 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42502537216; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:00:16,549 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42502094848; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=10332)\u001b[0m Epoch: 0|Train Loss: -1.855073881149292|Val Loss: -1.5001358865575702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:00:26,560 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42501656576; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:00:36,571 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42501103616; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_de pid=9889)\u001b[0m Epoch: 1|Train Loss: -1.7334696054458618|Val Loss: -1.451615428046821\n",
      "\u001b[2m\u001b[36m(train_de pid=10238)\u001b[0m Epoch: 0|Train Loss: -1.6186848163604737|Val Loss: -1.3958876033773706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:00:46,582 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42500661248; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:00:56,593 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42500231168; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:01:06,604 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42499674112; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:01:16,616 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42499219456; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:01:26,626 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42498768896; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:01:36,638 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42498289664; capacity: 1006450962432. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-12-07 17:01:46,649 E 9002 9022] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-12-07_16-54-24_461926_8758 is over 95% full, available space: 42497814528; capacity: 1006450962432. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "main(500,500)\n",
    "#  Stop Ray\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39SAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
